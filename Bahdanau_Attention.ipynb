{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fd5031e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27c44b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60340200",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc4457fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "070c2301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 RNN 클래스 (GRU 기반)\n",
    "# 입력 문장을 임베딩 후, GRU를 이용해 시퀀스 전체를 인코딩하고, 디코더가 사용할 context 정보를 반환한다.\n",
    "class EncoderRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        input_size (int): 입력 어휘 사전의 크기 (vocab size)\n",
    "        hidden_size (int): GRU hidden state의 차원\n",
    "        dropout_p (float, optional): 드롭아웃 비율 (기본값 0.1)\n",
    "\n",
    "    Inputs:\n",
    "        input (Tensor): [batch_size, seq_len] 형태의 입력 시퀀스 (단어 인덱스)\n",
    "\n",
    "    Returns:\n",
    "        output (Tensor): [batch_size, seq_len, hidden_size], 각 time step의 hidden state\n",
    "        hidden (Tensor): [1, batch_size, hidden_size], 마지막 hidden state (디코더 초기값)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # 단어 인덱스를 임베딩 벡터로 변환 (임베딩 차원 = hidden_size)\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "\n",
    "        # GRU 셀 (batch_first=True: 입력이 [batch, seq, feature] 형태)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "\n",
    "        # Dropout: 학습 중 일부 뉴런 무작위 비활성화로 과적합 방지\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "\n",
    "    def forward(self, input):    # input: [batch_size, seq_len]\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input (Tensor): [batch_size, seq_len] 형태의 단어 인덱스 텐서\n",
    "\n",
    "        Returns:\n",
    "            output (Tensor): GRU의 전체 출력, [batch_size, seq_len, hidden_size]\n",
    "            hidden (Tensor): 마지막 hidden state, [1, batch_size, hidden_size]\n",
    "        \"\"\"\n",
    "\n",
    "        # 입력 임베딩 후 드롭아웃 적용\n",
    "        embedded = self.dropout(self.embedding(input))    # [batch_size, seq_len, hidden_size]\n",
    "\n",
    "        # GRU를 통해 시퀀스를 따라 상태 계산\n",
    "        output, hidden = self.gru(embedded)\n",
    "\n",
    "        # 전체 시퀀스 출력 + 마지막 hidden state 반환\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69679acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bahdanau (Additive) Attention 구현 클래스\n",
    "# 쿼리(디코더 상태)와 키(인코더 출력)를 비교하여 어텐션 가중치(집중 정도)를 계산하고, 컨텍스트 벡터를 생성한다.\n",
    "\n",
    "class BahdanauAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        hidden_size (int): 쿼리 및 키의 hidden state 차원\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "\n",
    "        # query (디코더 hidden) 변환\n",
    "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "        # key (인코더 출력) 변환\n",
    "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "        # 유사도 점수 계산용 선형 변환\n",
    "        self.Va = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, query, keys):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            query (Tensor): 디코더 hidden state  \n",
    "                            shape = [batch_size, 1, hidden_size]\n",
    "\n",
    "            keys (Tensor): 인코더의 전체 출력 시퀀스  \n",
    "                           shape = [batch_size, seq_len, hidden_size]\n",
    "\n",
    "        Returns:\n",
    "            context (Tensor): 가중합된 인코더 출력 (컨텍스트 벡터)  \n",
    "                              shape = [batch_size, 1, hidden_size]\n",
    "\n",
    "            weights (Tensor): 어텐션 가중치  \n",
    "                              shape = [batch_size, 1, seq_len]\n",
    "        \"\"\"\n",
    "\n",
    "        # Wa(query): [batch, 1, hidden], Ua(keys): [batch, seq_len, hidden]\n",
    "        # broadcast 되어 결과 shape: [batch, seq_len, hidden]\n",
    "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))    # [batch, seq_len, 1]\n",
    "\n",
    "        # softmax를 위해 차원 조정\n",
    "        scores = scores.squeeze(2).unsqueeze(1)    # [batch, 1, seq_len]\n",
    "\n",
    "        # softmax를 통해 정규화된 어텐션 가중치 계산\n",
    "        weights = F.softmax(scores, dim=-1)    # [batch, 1, seq_len]\n",
    "\n",
    "        # 어텐션 가중치를 인코더 출력(keys)에 곱해 컨텍스트 벡터 계산\n",
    "        # keys: [batch, seq_len, hidden], weights: [batch, 1, seq_len]\n",
    "        context = torch.bmm(weights, keys)    # [batch, 1, hidden]\n",
    "\n",
    "        return context, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f9f62c",
   "metadata": {},
   "source": [
    "### **[INSIGHT]**\n",
    "- Additive 방식은 내적(dot-product) 방식보다 벡터 간 관계를 비선형적으로 표현할 수 있어 표현력이 풍부하다.\n",
    "- 각 입력 위치에 얼마나 집중할지를 학습 가능한 방식으로 계산한다.\n",
    "\n",
    "#### **<attention score 계산 시, **tanh**을 사용하는 이유>**\n",
    "여기서 tanh를 제거하면 두 벡터 간 선형 관계를 측정하는 단순 모델이 되지만, tanh를 넣으면 쿼리와 키 사이의 복잡한 상호작용(ex.문맥적 중요성)의 반영이 가능해진다. 이를 통해 attention 가중치가 더 세밀하게 조정되어 모델의 성능이 향상된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed9c37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bahdanau 어텐션을 활용한 GRU 기반 디코더 클래스\n",
    "# 인코더의 출력과 디코더의 현재 상태를 이용해 어텐션을 적용하고, 이를 통해 매 시점마다 단어를 하나씩 생성한다.\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        hidden_size (int): hidden state 차원\n",
    "        output_size (int): 출력 어휘 수 (target vocabulary size)\n",
    "        dropout_p (float): 드롭아웃 확률\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "\n",
    "        # Bahdanau 어텐션 모듈\n",
    "        self.attention = BahdanauAttention(hidden_size)\n",
    "\n",
    "        # context vector (hidden_size) + embedding (hidden_size) → 2 * hidden_size\n",
    "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
    "\n",
    "        # GRU 출력 → 단어 분포 예측\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            encoder_outputs (Tensor): 인코더의 전체 출력 [batch, seq_len, hidden_size]\n",
    "            encoder_hidden (Tensor): 인코더의 마지막 hidden state [1, batch, hidden_size]\n",
    "            target_tensor (Tensor or None): 교사 강요용 정답 시퀀스 [batch, MAX_LENGTH]\n",
    "\n",
    "        Returns:\n",
    "            decoder_outputs (Tensor): 전체 출력 시퀀스의 단어 분포 [batch, MAX_LENGTH, output_size]\n",
    "            decoder_hidden (Tensor): 마지막 hidden state [1, batch, hidden_size]\n",
    "            attentions (Tensor): 어텐션 가중치 모음 [batch, MAX_LENGTH, seq_len]\n",
    "        \"\"\"\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "\n",
    "        # 디코더의 첫 입력 = <SOS> 토큰\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []  # 예측된 단어 분포 저장\n",
    "        attentions = []       # 어텐션 가중치 저장\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            # 1 step 디코딩\n",
    "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "\n",
    "            decoder_outputs.append(decoder_output)    # decoder_output: [batch, 1, output_size]\n",
    "            attentions.append(attn_weights)           # attn_weights: [batch, 1, seq_len]\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: 정답 토큰을 다음 입력으로 사용\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1)  # [batch, 1]\n",
    "            else:\n",
    "                # 예측 결과를 다음 입력으로 사용\n",
    "                _, topi = decoder_output.topk(1)  # topi: [batch, 1, 1]\n",
    "                decoder_input = topi.squeeze(-1).detach()  # [batch, 1]\n",
    "\n",
    "        # 시간 차원으로 연결\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)  # [batch, MAX_LENGTH, output_size]\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "\n",
    "        attentions = torch.cat(attentions, dim=1)  # [batch, MAX_LENGTH, seq_len]\n",
    "\n",
    "        return decoder_outputs, decoder_hidden, attentions\n",
    "\n",
    "    def forward_step(self, input, hidden, encoder_outputs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input (Tensor): 현재 입력 토큰 [batch, 1]\n",
    "            hidden (Tensor): 이전 hidden state [1, batch, hidden_size]\n",
    "            encoder_outputs (Tensor): 인코더 전체 출력 [batch, seq_len, hidden_size]\n",
    "\n",
    "        Returns:\n",
    "            output (Tensor): 예측 단어 분포 [batch, 1, output_size]\n",
    "            hidden (Tensor): 업데이트된 hidden state [1, batch, hidden_size]\n",
    "            attn_weights (Tensor): 어텐션 가중치 [batch, 1, seq_len]\n",
    "        \"\"\"\n",
    "\n",
    "        # 입력 토큰을 임베딩 후 드롭아웃 적용\n",
    "        embedded = self.dropout(self.embedding(input))    # [batch, 1, hidden_size]\n",
    "\n",
    "        # hidden: [1, batch, hidden_size] → [batch, 1, hidden_size] (쿼리로 사용하기 위해 차원 전치)\n",
    "        query = hidden.permute(1, 0, 2)\n",
    "\n",
    "        # 어텐션 계산: context: [batch, 1, hidden_size], attn_weights: [batch, 1, seq_len]\n",
    "        context, attn_weights = self.attention(query, encoder_outputs)\n",
    "\n",
    "        # context와 임베딩을 연결 → GRU 입력 준비\n",
    "        input_gru = torch.cat((embedded, context), dim=2)    # [batch, 1, 2 * hidden_size]\n",
    "\n",
    "        # GRU 계산\n",
    "        output, hidden = self.gru(input_gru, hidden)  # output: [batch, 1, hidden_size]\n",
    "\n",
    "        # 출력층: 단어 분포 계산\n",
    "        output = self.out(output)  # [batch, 1, output_size]\n",
    "\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9652e3e5",
   "metadata": {},
   "source": [
    "### **[INSIGHT]**\n",
    "- forward_step() 분리로 재사용성과 가독성 향상\n",
    "- 어텐션은 decoder가 매 시점마다 encoder의 전체 정보를 동적으로 참고하게 한다.\n",
    "\n",
    "#### **<\"decoder_input = topi.squeeze(-1).detach()\"에서 '.detach()'을 사용한 이유>**\n",
    "해당 텐서를 계산 그래프에서 분리해 역전파시 사용하지 않도록 한다. 그 이유는 학습 시, 이 출력 값을 다음 입력으로 사용하는 것일 뿐, 다시 학습 대상으로 삼을 필요가 없기 때문이다. 만약 학습 대상으로 하게 될 경우, gradient가 두 번 흐르게 됨으로 비효율적이고 잘못된 학습으로 이어질 수 있다.\n",
    "\n",
    "-----\n",
    "#### **<\"input_gru = torch.cat((embedded, context), dim=2)\"에서 GRU 입력으로 context와 임베딩을 cat해서 사용한 이유>**\n",
    "디코더는 현재 시점의 토큰(=임베딩)만으로 다음 토큰을 예측하기엔 정보가 부족할 수 있다. 그래서 context와 토큰(임베딩)을 결합하여 더 풍부한 정보를 기반으로 디코딩하기 위함이다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40231254",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(J_Note)",
   "language": "python",
   "name": "j_note"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
